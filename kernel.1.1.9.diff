diff -ru linux/include/linux/vm86.h linux.new/include/linux/vm86.h
--- linux/include/linux/vm86.h	Wed Apr 27 08:53:19 1994
+++ linux.new/include/linux/vm86.h	Wed Apr 27 08:48:34 1994
@@ -40,7 +40,7 @@
 #define VM86_SIGNAL	0	/* return due to signal */
 #define VM86_UNKNOWN	1	/* unhandled GP fault - IO-instruction or similar */
 #define VM86_INTx	2	/* int3/int x instruction (ARG = x) */
-#define VM86_STI	3	/* sti/popfl instruction enabled virtual interrupts */
+#define VM86_STI	3	/* sti/popfl/iret instruction enabled virtual interrupts */
 
 /*
  * This is the stack-layout when we have done a "SAVE_ALL" from vm86
diff -ru linux/kernel/vm86.c linux.new/kernel/vm86.c
--- linux/kernel/vm86.c	Wed Apr 27 08:53:19 1994
+++ linux.new/kernel/vm86.c	Tue Apr 26 21:13:54 1994
@@ -22,14 +22,23 @@
 /*
  * virtual flags (16 and 32-bit versions)
  */
-#define VFLAGS(regs)	(*(unsigned short *)&(current->v86flags))
-#define VEFLAGS(regs)	(current->v86flags)
+#define VFLAGS		(*(unsigned short *)&(current->v86flags))
+#define VEFLAGS		(current->v86flags)
 
 #define set_flags(X,new,mask) \
 ((X) = ((X) & ~(mask)) | ((new) & (mask)))
 
 #define SAFE_MASK	(0xDD5)
 
+static inline unsigned long get_vflags(struct vm86_regs * regs)
+{
+	unsigned long flags = regs->eflags & SAFE_MASK;
+
+	if (current->v86flags & VIF_MASK)
+		flags |= IF_MASK;
+	return flags | (VEFLAGS & current->v86mask);
+}
+
 asmlinkage struct pt_regs * save_v86_state(struct vm86_regs * regs)
 {
 	unsigned long tmp;
@@ -39,6 +48,7 @@
 		do_exit(SIGSEGV);
 	}
 	memcpy_tofs(&current->vm86_info->regs,regs,sizeof(*regs));
+	put_fs_long(get_vflags(regs),&current->vm86_info->regs.eflags);
 	put_fs_long(current->screen_bitmap,&current->vm86_info->screen_bitmap);
 	tmp = current->tss.esp0;
 	current->tss.esp0 = current->saved_kernel_stack;
@@ -91,7 +101,9 @@
  * has set it up safely, so this makes sure interrupt etc flags are
  * inherited from protected mode.
  */
- 	current->v86flags = info.regs.eflags;
+ 	current->v86flags = info.regs.eflags & ~VIF_MASK;
+	if (info.regs.eflags & IF_MASK)
+		current->v86flags |= VIF_MASK;
 	info.regs.eflags &= SAFE_MASK;
 	info.regs.eflags |= ~SAFE_MASK & pt_regs->eflags;
 	info.regs.eflags |= VM_MASK;
@@ -159,7 +171,7 @@
 
 static inline void set_vflags_long(unsigned long eflags, struct vm86_regs * regs)
 {
-	set_flags(VEFLAGS(regs), eflags, current->v86mask);
+	set_flags(VEFLAGS, eflags, current->v86mask);
 	set_flags(regs->eflags, eflags, SAFE_MASK);
 	if (eflags & IF_MASK)
 		set_IF(regs);
@@ -167,19 +179,10 @@
 
 static inline void set_vflags_short(unsigned short flags, struct vm86_regs * regs)
 {
-	set_flags(VFLAGS(regs), flags, current->v86mask);
+	set_flags(VFLAGS, flags, current->v86mask);
 	set_flags(regs->eflags, flags, SAFE_MASK);
 	if (flags & IF_MASK)
 		set_IF(regs);
-}
-
-static inline unsigned long get_vflags(struct vm86_regs * regs)
-{
-	unsigned long flags = regs->eflags & SAFE_MASK;
-
-	if (current->v86flags & VIF_MASK)
-		flags |= IF_MASK;
-	return flags | (VEFLAGS(regs) & current->v86mask);
 }
 
 /*
